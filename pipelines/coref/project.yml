title: "spaCy Coref Model"
description: >
  This project trains a coreference model for spaCy using OntoNotes.

vars:
  # XXX Change to your actual GPU ID
  gpu_id: 0
  # XXX fill with your local path to OntoNotes
  ontonotes: /home/akos/ontonotes5/data
  max_epochs: 20

directories: ["assets", "corpus", "scripts", "configs", "training"]

assets:
  - dest: "assets/"
    git:
      repo: "https://github.com/explosion/conll-2012"
      branch: "main"
      path: ""
    description: "CoNLL-2012 scripts and dehydrated data."
  - dest: "assets/conll-eval"
    git:
      repo: "https://github.com/conll/reference-coreference-scorers"
      branch: "master"
      path: ""
    description: "CoNLL-2012 reference scorer."

workflows:
  prep:
    - prep-data
    - preprocess
  train:
    - train-cluster
    - prep-span-data
    - train-span-predictor
    - assemble

  all:
    # prep
    - prep-data
    - preprocess
    # train
    - train-cluster
    - prep-span-data
    - train-span-predictor
    - assemble

commands:
  - name: "prep-data"
    help: "Rehydrate the data using OntoNotes"
    script: 
      # XXX python2 is required for the old scripts
      - python2 -c "print('Checking for Python 2...')"
      - tar xzf assets/conll-2012-development.v4.tar.gz -C assets/
      - tar xzf assets/conll-2012-test-key.tar.gz -C assets/
      - tar xzf assets/conll-2012-test-official.v9.tar.gz -C assets/
      - tar xzf assets/conll-2012-train.v4.tar.gz -C assets/
      #- tar xvzf assets/conll2012-coref/reference-coreference-scorers.v8.01.tar.gz -C assets/

      - echo "Rehydrating data... This will take roughly 20 minutes"
      - "bash assets/conll-2012/v3/scripts/skeleton2conll.sh -D ${vars.ontonotes} assets/conll-2012"

      # Concatenate the data into single files to make it easier to work with
      - sh -c "rm -f assets/*._gold_conll"
      - sh -c "cat assets/conll-2012/v4/data/development/data/english/annotations/*/*/*/*.v4_gold_conll >> assets/dev.gold.conll"
      - sh -c "cat assets/conll-2012/v4/data/train/data/english/annotations/*/*/*/*.v4_gold_conll >> assets/train.gold.conll"
      - sh -c "cat assets/conll-2012/v4/data/test/data/english/annotations/*/*/*/*.v4_gold_conll >> assets/test.gold.conll"
    deps:
      - ${vars.ontonotes}
    outputs: 
      - "assets/train.gold.conll"
      - "assets/dev.gold.conll"
      - "assets/test.gold.conll"

  - name: "preprocess"
    help: "Convert the data to spaCy's format"
    script:
      - python scripts/preprocess.py assets/train.gold.conll corpus/train.spacy
      - python scripts/preprocess.py assets/dev.gold.conll corpus/dev.spacy
      - python scripts/preprocess.py assets/test.gold.conll corpus/test.spacy

  - name: "train-cluster"
    help: "Train the clustering component"
    script: 
      - "python -m spacy train configs/cluster.cfg -g ${vars.gpu_id} --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy -o training/cluster --training.max_epochs ${vars.max_epochs}"
    deps:
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
      - "configs/cluster.cfg"
    outputs:
      - "training/model-best"
  
  - name: "prep-span-data"
    help: "Prepare data for the span predictor component."
    script:
      - python scripts/reader.py --model-path training/cluster/model-best/ --gpu --input-path corpus/train.spacy --output-path corpus/spans.train.spacy --head-prefix coref_head_clusters --span-prefix coref_clusters
      - python scripts/reader.py --model-path training/cluster/model-best/ --gpu --input-path corpus/dev.spacy --output-path corpus/spans.dev.spacy --head-prefix coref_head_clusters --span-prefix coref_clusters
    deps:
      - corpus/train.spacy
      - corpus/dev.spacy
    outputs:
      - corpus/spans.train.spacy
      - corpus/spans.dev.spacy
  
  - name: "train-span-predictor"
    help: "Train the span predictor component."
    script:
      - spacy train configs/span.cfg -c scripts/custom_functions.py -g ${vars.gpu_id} --paths.train corpus/spans.train.spacy --paths.dev corpus/spans.dev.spacy --training.max_epochs ${vars.max_epochs} --paths.transformer_source training/cluster/model-best -o training/span_predictor
    deps:
      - corpus/spans.train.spacy
      - corpus/spans.dev.spacy
    outputs:
      - training/span_predictor

  - name: "assemble"
    help: "Assemble parts into complete coref pipeline."
    script:
      - spacy assemble configs/coref.cfg training/coref

  - name: "eval"
    help: "Evaluate model on the test set."
    script:
      - rm -f corpus/test.key corpus/test.response
      - python scripts/run_eval.py training/coref corpus/test.spacy
