title: "Spancat datasets"
description: |
  This project compiles various NER and more general spancat datasets 
  and their converters into the [spaCy format](https://spacy.io/api/data-formats). 
  You can use this to try out experiment with `ner` and `spancat`
  or to potentially pre-train them for your application.

vars:
  spans_key: "sc"
  gpu_id: 0

directories:
  - "assets"
  - "configs"
  - "corpus/spancat"
  - "corpus/ner"
  - "scripts"
  - "analyses"
  - "unseen"

workflows:
  wnut17:
    - "preprocess-wnut17"
    - "convert-wnut17-ents"
    - "convert-wnut17-spans"
    - "inspect-wnut17"
  wikineural:
    - "clean-wikineural"
    - "convert-wikineural-ents"
    - "convert-wikineural-spans"
  conll:
    - "unpack-conll"
    - "preprocess-conll"
    - "convert-conll-ents"
    - "convert-conll-spans"
    - "inspect-conll"
  archaeo:
    - "convert-archaeo-ents"
    - "convert-archaeo-spans"
    - "clean-archaeo"
    - "inspect-archaeo"
  anem:
    - "convert-anem-ents"
    - "convert-anem-spans"
    - "inspect-anem"
  finer:
    - "unpack-finer"
    - "convert-finer-ents"
    - "convert-finer-spans"
    - "inspect-finer"
  all:
    - "preprocess-wnut17"
    - "convert-wnut17-ents"
    - "convert-wnut17-spans"
    - "clean-wikineural"
    - "convert-wikineural-ents"
    - "convert-wikineural-spans"
    - "unpack-conll"
    - "convert-conll-spans"
    - "convert-conll-ents"
    - "convert-archaeo-ents"
    - "convert-archaeo-spans"
    - "convert-anem-ents"
    - "convert-anem-spans"
    - "unpack-finer"
    - "convert-finer-ents"
    - "convert-finer-spans"
    - "inspect-finer"

assets:
  # WNUT17 https://aclanthology.org/W17-4418/
  - dest: "assets/wnut17-train.iob"
    url: "https://github.com/leondz/emerging_entities_17/blob/master/wnut17train.conll"
  - dest: "assets/wnut17-test.iob"
    url: "https://github.com/leondz/emerging_entities_17/blob/master/emerging.test.annotated"
  - dest: "assets/wnut17-dev.iob"
    url: "https://github.com/leondz/emerging_entities_17/blob/master/emerging.dev.conll"
  ### Wikineural datasets https://aclanthology.org/2021.findings-emnlp.215/ ###
  # Wikineural (en)
  - dest: "assets/raw-en-wikineural-train.iob"
    description: "WikiNeural (en) training dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/en/train.conllu
  - dest: "assets/raw-en-wikineural-dev.iob"
    description: "WikiNeural (en) dev dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/en/val.conllu
  - dest: "assets/raw-en-wikineural-test.iob"
    description: "WikiNeural (en) test dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/en/test.conllu
  # Wikineural (de)
  - dest: "assets/raw-de-wikineural-train.iob"
    description: "WikiNeural (de) training dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/de/train.conllu
  - dest: "assets/raw-de-wikineural-dev.iob"
    description: "WikiNeural (de) dev dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/de/val.conllu
  - dest: "assets/raw-de-wikineural-test.iob"
    description: "WikiNeural (de) test dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/de/test.conllu
  # Wikineural (es)
  - dest: "assets/raw-es-wikineural-train.iob"
    description: "WikiNeural (es) training dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/es/train.conllu
  - dest: "assets/raw-es-wikineural-dev.iob"
    description: "WikiNeural (es) dev dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/es/val.conllu
  - dest: "assets/raw-es-wikineural-test.iob"
    description: "WikiNeural (es) test dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/es/test.conllu
  # Wikineural (nl)
  - dest: "assets/raw-nl-wikineural-train.iob"
    description: "WikiNeural (nl) training dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/nl/train.conllu
  - dest: "assets/raw-nl-wikineural-dev.iob"
    description: "WikiNeural (nl) dev dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/nl/val.conllu
  - dest: "assets/raw-nl-wikineural-test.iob"
    description: "WikiNeural (nl) test dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/nl/test.conllu
  # CoNLL-2002 (es, nl) https://aclanthology.org/W02-2024/
  - dest: "assets/conll.tgz"
    description: "ConLL 2002 shared task data."
    url: http://www.cnts.ua.ac.be/conll2002/ner.tgz
  ### Archaeo dataset https://aclanthology.org/2020.lrec-1.562/ ###
  - dest: "assets/archaeo.bio"
    description: "Dutch Archaeological NER dataset by Alex Brandsen (LREC 2020)"
    url: https://github.com/alexbrandsen/dutch-archaeo-NER-dataset/blob/master/complete-bio-gs.bio
  ### AnEM dataset https://aclanthology.org/W12-4304/ ###
  - dest: "assets/anem-train.iob"
    url: "https://github.com/openbiocorpora/anem/blob/master/original-data/test/AnEM.train"
  - dest: "assets/anem-test.iob"
    url: "https://github.com/openbiocorpora/anem/blob/master/original-data/test/AnEM.test"
  ### FiNER https://aclanthology.org/2022.acl-long.303/ ###
  - dest: "assets/finer139.zip"
    url: "https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/finer139.zip"


commands:

  - name: "preprocess-wnut17"
    help: "Canonicalize the WNUT2017 data set for conversion to .spacy."
    script:
      - python -m scripts.preprocess assets/wnut17-train.iob assets/wnut17-train.iob
      - python -m scripts.preprocess assets/wnut17-dev.iob assets/wnut17-dev.iob
      - python -m scripts.preprocess assets/wnut17-test.iob assets/wnut17-test.iob
    deps:
      - assets/wnut17-train.iob
      - assets/wnut17-dev.iob
      - assets/wnut17-test.iob
    outputs:
      - assets/wnut17-train.iob
      - assets/wnut17-dev.iob
      - assets/wnut17-test.iob
      
  - name: "convert-wnut17-ents"
    help: "Convert WNUT17 dataset into the spaCy format"
    script:
      - >-
        python -m scripts.convert_to_spans
        assets/wnut17-train.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/wnut17-dev.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/wnut17-test.iob corpus/ner/
        --use-ents
    deps:
      - assets/wnut17-train.iob
      - assets/wnut17-dev.iob
      - assets/wnut17-test.iob
    outputs:
      - corpus/ner/wnut17-train.spacy
      - corpus/ner/wnut17-dev.spacy
      - corpus/ner/wnut17-test.spacy

  - name: "convert-wnut17-spans"
    help: "Convert WNUT17 dataset into the spaCy format"
    script:
      - >-
        python -m scripts.convert_to_spans
        assets/wnut17-train.iob corpus/spancat/
        --spans-key ${vars.spans_key}
      - >-
        python -m scripts.convert_to_spans
        assets/wnut17-dev.iob corpus/spancat/
        --spans-key ${vars.spans_key}
      - >-
        python -m scripts.convert_to_spans
        assets/wnut17-test.iob corpus/spancat/
        --spans-key ${vars.spans_key}
    deps:
      - assets/wnut17-train.iob
      - assets/wnut17-dev.iob
      - assets/wnut17-test.iob
    outputs:
      - corpus/spancat/wnut17-train.spacy
      - corpus/spancat/wnut17-dev.spacy
      - corpus/spancat/wnut17-test.spacy

  - name: "inspect-wnut17"
    help: "Analyze span-characteristics"
    script:
      - >-
        python -m spacy debug data configs/spancat_default.cfg 
        --paths.train corpus/spancat/wnut17-train.spacy 
        --paths.dev corpus/spancat/wnut17-dev.spacy
  - name: "clean-wikineural"
    help: "Remove unnecessary indices from wikineural data"
    script:
      # Clean Wikineural datasets
      - >- 
        python -m scripts.preprocess
        assets/raw-de-wikineural-train.iob
        assets/de-wikineural-train.iob
        --strip-digits
      - >-
        python -m scripts.preprocess
        assets/raw-de-wikineural-dev.iob
        assets/de-wikineural-dev.iob
        --strip-digits
      - >-
        python -m scripts.preprocess
        assets/raw-de-wikineural-test.iob
        assets/de-wikineural-test.iob
        --strip-digits
      - >-
        python -m scripts.preprocess
        assets/raw-en-wikineural-train.iob
        assets/en-wikineural-train.iob
        --strip-digits
      - >- 
        python -m scripts.preprocess
        assets/raw-en-wikineural-dev.iob
        assets/en-wikineural-dev.iob
        --strip-digits
      - >-
        python -m scripts.preprocess
        assets/raw-en-wikineural-test.iob
        assets/en-wikineural-test.iob
        --strip-digits
      - >- 
        python -m scripts.preprocess
        assets/raw-es-wikineural-train.iob
        assets/es-wikineural-train.iob
        --strip-digits
      - >-
        python -m scripts.preprocess
        assets/raw-es-wikineural-dev.iob
        assets/es-wikineural-dev.iob
        --strip-digits
      - >- 
        python -m scripts.preprocess
        assets/raw-es-wikineural-test.iob
        assets/es-wikineural-test.iob
        --strip-digits
      - >- 
        python -m scripts.preprocess
        assets/raw-nl-wikineural-train.iob
        assets/nl-wikineural-train.iob
        --strip-digits
      - >- 
        python -m scripts.preprocess
        assets/raw-nl-wikineural-dev.iob
        assets/nl-wikineural-dev.iob
      - >-
        python -m scripts.preprocess
        assets/raw-nl-wikineural-test.iob
        assets/nl-wikineural-test.iob
        --strip-digits
    deps:
      # Wikineural datasets
      - assets/raw-de-wikineural-train.iob
      - assets/raw-de-wikineural-dev.iob
      - assets/raw-de-wikineural-test.iob
      - assets/raw-en-wikineural-train.iob
      - assets/raw-en-wikineural-dev.iob
      - assets/raw-en-wikineural-test.iob
      - assets/raw-es-wikineural-train.iob
      - assets/raw-es-wikineural-dev.iob
      - assets/raw-es-wikineural-test.iob
      - assets/raw-nl-wikineural-train.iob
      - assets/raw-nl-wikineural-dev.iob
      - assets/raw-nl-wikineural-test.iob
    outputs:
      # Cleaned Wikineural datasets
      - assets/de-wikineural-train.iob
      - assets/de-wikineural-dev.iob
      - assets/de-wikineural-test.iob
      - assets/en-wikineural-train.iob
      - assets/en-wikineural-dev.iob
      - assets/en-wikineural-test.iob
      - assets/es-wikineural-train.iob
      - assets/es-wikineural-dev.iob
      - assets/es-wikineural-test.iob
      - assets/nl-wikineural-train.iob
      - assets/nl-wikineural-dev.iob
      - assets/nl-wikineural-test.iob

  - name: "convert-wikineural-spans"
    help: "Convert WikiNeural dataset (de, en, es, nl) into the spaCy format"
    script:
      - >-
        python -m scripts.convert_to_spans
        assets/de-wikineural-train.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/de-wikineural-dev.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/de-wikineural-test.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/en-wikineural-train.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/en-wikineural-dev.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/en-wikineural-test.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/es-wikineural-train.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/es-wikineural-dev.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/es-wikineural-test.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/nl-wikineural-train.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/nl-wikineural-dev.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/nl-wikineural-test.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
    deps:
      - "assets/de-wikineural-train.iob"
      - "assets/de-wikineural-dev.iob"
      - "assets/de-wikineural-test.iob"
      - "assets/en-wikineural-train.iob"
      - "assets/en-wikineural-dev.iob"
      - "assets/en-wikineural-test.iob"
      - "assets/es-wikineural-train.iob"
      - "assets/es-wikineural-dev.iob"
      - "assets/es-wikineural-test.iob"
      - "assets/nl-wikineural-train.iob"
      - "assets/nl-wikineural-dev.iob"
      - "assets/nl-wikineural-test.iob"
    outputs:
      - "corpus/spancat/de-wikineural-train.spacy"
      - "corpus/spancat/de-wikineural-dev.spacy"
      - "corpus/spancat/de-wikineural-test.spacy"
      - "corpus/spancat/en-wikineural-train.spacy"
      - "corpus/spancat/en-wikineural-dev.spacy"
      - "corpus/spancat/en-wikineural-test.spacy"
      - "corpus/spancat/es-wikineural-train.spacy"
      - "corpus/spancat/es-wikineural-dev.spacy"
      - "corpus/spancat/es-wikineural-test.spacy"
      - "corpus/spancat/nl-wikineural-train.spacy"
      - "corpus/spancat/nl-wikineural-dev.spacy"
      - "corpus/spancat/nl-wikineural-test.spacy"

  - name: "convert-wikineural-ents"
    help: "Convert WikiNeural dataset (de, en, es, nl) into the spaCy format"
    script:
      # Convert de dataset
      - >-
        python -m scripts.convert_to_spans
        assets/de-wikineural-train.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/de-wikineural-dev.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/de-wikineural-test.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/de-wikineural-test.iob corpus/spancat/
        --use-ents
      # Convert en dataset
      - >-
        python -m scripts.convert_to_spans
        assets/en-wikineural-train.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/en-wikineural-dev.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/en-wikineural-test.iob corpus/ner/
        --use-ents
      # Convert es dataset
      - >-
        python -m scripts.convert_to_spans
        assets/es-wikineural-train.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/es-wikineural-dev.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/es-wikineural-test.iob corpus/ner/
        --use-ents
      # Convert nl dataset
      - >-
        python -m scripts.convert_to_spans
        assets/nl-wikineural-train.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/nl-wikineural-dev.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/nl-wikineural-test.iob corpus/ner/
        --use-ents
    deps:
      - "assets/de-wikineural-train.iob"
      - "assets/de-wikineural-dev.iob"
      - "assets/de-wikineural-test.iob"
      - "assets/en-wikineural-train.iob"
      - "assets/en-wikineural-dev.iob"
      - "assets/en-wikineural-test.iob"
      - "assets/es-wikineural-train.iob"
      - "assets/es-wikineural-dev.iob"
      - "assets/es-wikineural-test.iob"
      - "assets/nl-wikineural-train.iob"
      - "assets/nl-wikineural-dev.iob"
      - "assets/nl-wikineural-test.iob"
    outputs:
      - "corpus/ner/de-wikineural-train.spacy"
      - "corpus/ner/de-wikineural-dev.spacy"
      - "corpus/spancat/de-wikineural-test.spacy"
      - "corpus/ner/en-wikineural-train.spacy"
      - "corpus/ner/en-wikineural-dev.spacy"
      - "corpus/ner/en-wikineural-test.spacy"
      - "corpus/ner/es-wikineural-train.spacy"
      - "corpus/ner/es-wikineural-dev.spacy"
      - "corpus/ner/es-wikineural-test.spacy"
      - "corpus/ner/nl-wikineural-train.spacy"
      - "corpus/ner/nl-wikineural-dev.spacy"
      - "corpus/ner/nl-wikineural-test.spacy"
  
  - name: "inspect-wikineural"
    help: "Analyze span-characteristics"
    script:
      - >-
        python -m spacy debug data configs/spancat_default.cfg 
        --paths.train corpus/spancat/de-wikineural-train.spacy 
        --paths.dev corpus/spancat/de-wikineural-dev.spacy
      
      - >-
        python -m spacy debug data configs/spancat_default.cfg 
        --paths.train corpus/spancat/en-wikineural-train.spacy 
        --paths.dev corpus/spancat/en-wikineural-dev.spacy
      
      - >-
        python -m spacy debug data configs/spancat_default.cfg 
        --paths.train corpus/spancat/es-wikineural-train.spacy 
        --paths.dev corpus/spancat/es-wikineural-dev.spacy
      
      - >-
        python -m spacy debug data configs/spancat_default.cfg 
        --paths.train corpus/spancat/nl-wikineural-train.spacy 
        --paths.dev corpus/spancat/nl-wikineural-dev.spacy


  - name: "unpack-conll"
    help: "Decompress ConLL 2002, remove temporary files and change encoding."
    script:
      - mkdir temp
      - tar -xvf assets/conll.tgz -C temp
      - gzip -d temp/ner/data/esp.testa.gz 
      - gzip -d temp/ner/data/esp.testb.gz
      - gzip -d temp/ner/data/esp.train.gz
      - gzip -d temp/ner/data/ned.testa.gz
      - gzip -d temp/ner/data/ned.testb.gz
      - gzip -d temp/ner/data/ned.train.gz
      - iconv -f iso-8859-1 temp/ner/data/esp.testa -o assets/es-conll-dev.iob
      - iconv -f iso-8859-1 temp/ner/data/esp.testb -o assets/es-conll-test.iob
      - iconv -f iso-8859-1 temp/ner/data/esp.train -o assets/es-conll-train.iob
      - iconv -f iso-8859-1 temp/ner/data/ned.testa -o assets/nl-conll-dev.iob
      - iconv -f iso-8859-1 temp/ner/data/ned.testb -o assets/nl-conll-test.iob
      - iconv -f iso-8859-1 temp/ner/data/ned.train -o assets/nl-conll-train.iob
      - rm -rf temp
      - rm assets/conll.tgz
    deps:
      - assets/conll.tgz
    outputs:
      # Cleaned CoNLL datasets
      - assets/es-conll-train.iob
      - assets/es-conll-dev.iob
      - assets/es-conll-test.iob
      - assets/nl-conll-train.iob
      - assets/nl-conll-dev.iob
      - assets/nl-conll-test.iob
  
  - name: "preprocess-conll"
    help: "Canonicalize the Dutch ConLL data set for conversion to .spacy."
    script:
      - python -m scripts.preprocess assets/nl-conll-train.iob assets/nl-conll-train.iob
      - python -m scripts.preprocess assets/nl-conll-dev.iob assets/nl-conll-dev.iob
      - python -m scripts.preprocess assets/nl-conll-test.iob assets/nl-conll-test.iob
    deps:
      - assets/nl-conll-train.iob
      - assets/nl-conll-dev.iob
      - assets/nl-conll-test.iob
    outputs:
      - assets/nl-conll-train.iob
      - assets/nl-conll-dev.iob
      - assets/nl-conll-test.iob

  - name: "convert-conll-spans"
    help: "Convert CoNLL dataset (de, en, es, nl) into the spaCy format"
    script:
      # Convert es dataset
      - >-
        python -m scripts.convert_to_spans
        assets/es-conll-train.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/es-conll-dev.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/es-conll-test.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      # Convert nl dataset
      - >-
        python -m scripts.convert_to_spans
        assets/nl-conll-train.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/nl-conll-dev.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
      - >-
        python -m scripts.convert_to_spans
        assets/nl-conll-test.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
    deps:
      - "assets/es-conll-train.iob"
      - "assets/es-conll-dev.iob"
      - "assets/es-conll-test.iob"
      - "assets/nl-conll-train.iob"
      - "assets/nl-conll-dev.iob"
      - "assets/nl-conll-test.iob"
    outputs:
      - "corpus/spancat/es-conll-train.spacy"
      - "corpus/spancat/es-conll-dev.spacy"
      - "corpus/spancat/es-conll-test.spacy"
      - "corpus/spancat/nl-conll-train.spacy"
      - "corpus/spancat/nl-conll-dev.spacy"
      - "corpus/spancat/nl-conll-test.spacy"

  - name: "convert-conll-ents"
    help: "Convert CoNLL dataset (de, en, es, nl) into the spaCy format"
    script:
      # Convert es dataset
      - >-
        python -m scripts.convert_to_spans
        assets/es-conll-train.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/es-conll-dev.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/es-conll-test.iob corpus/ner/
        --use-ents
      # Convert nl dataset
      - >-
        python -m scripts.convert_to_spans
        assets/nl-conll-train.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/nl-conll-dev.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/nl-conll-test.iob corpus/ner/
        --use-ents
    deps:
      - "assets/es-conll-train.iob"
      - "assets/es-conll-dev.iob"
      - "assets/es-conll-test.iob"
      - "assets/nl-conll-train.iob"
      - "assets/nl-conll-dev.iob"
      - "assets/nl-conll-test.iob"
    outputs:
      - "corpus/ner/es-conll-train.spacy"
      - "corpus/ner/es-conll-dev.spacy"
      - "corpus/ner/es-conll-test.spacy"
      - "corpus/ner/nl-conll-train.spacy"
      - "corpus/ner/nl-conll-dev.spacy"
      - "corpus/ner/nl-conll-test.spacy"
  
  - name: "inspect-conll"
    help: "Analyze span-characteristics"
    script:
      - >-
        python -m spacy debug data configs/spancat_default.cfg 
        --paths.train corpus/spancat/es-conll-train.spacy 
        --paths.dev corpus/spancat/es-conll-dev.spacy
      - >-
        python -m spacy debug data configs/spancat_default.cfg 
        --paths.train corpus/spancat/nl-conll-train.spacy 
        --paths.dev corpus/spancat/nl-conll-dev.spacy

  - name: "convert-archaeo-spans"
    help: "Convert Dutch Archaeology dataset into the spaCy format"
    script:
      - >-
        python -m scripts.convert_to_spans
        assets/archaeo.bio corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter iob
      - >-
        python -m scripts.split_docs
        corpus/spancat/archaeo.spacy corpus/spancat
        --seed 42
        --shuffle
    deps:
      - "assets/archaeo.bio"
    outputs:
      - "corpus/spancat/archaeo-train.spacy"
      - "corpus/spancat/archaeo-dev.spacy"
      - "corpus/spancat/archaeo-test.spacy"

  - name: "convert-archaeo-ents"
    help: "Convert Dutch Archaeology dataset into the spaCy format"
    script:
      - >-
        python -m scripts.convert_to_spans
        assets/archaeo.bio corpus/ner/
        --use-ents
        --converter iob
      - >-
        python -m scripts.split_docs
        corpus/ner/archaeo.spacy corpus/ner/
        --seed 42
        --shuffle
    deps:
      - "assets/archaeo.bio"
    outputs:
      - "corpus/ner/archaeo-train.spacy"
      - "corpus/ner/archaeo-dev.spacy"
      - "corpus/ner/archaeo-test.spacy"
  
  - name: "inspect-archaeo"
    help: "Analyze span-characteristics"
    script:
      - >-
        python -m spacy debug data configs/spancat_default.cfg 
        --paths.train corpus/spancat/archaeo-train.spacy 
        --paths.dev corpus/spancat/archaeo-dev.spacy
  
  - name: "clean-archaeo"
    script:
      - mv corpus/ner/archaeo.spacy assets/archaeo_ner.spacy
      - mv corpus/spancat/archaeo.spacy assets/archaeo_span.spacy

  - name: "convert-anem-spans"
    help: "Convert AnEM dataset into the spaCy format"
    script:
      - >-
        python -m scripts.convert_to_spans
        assets/anem-train.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
        --train-size 0.8
        --seed 42
        --shuffle
      - mv corpus/spancat/anem-train-dev.spacy corpus/spancat/anem-dev.spacy
      - >-
        python -m scripts.convert_to_spans
        assets/anem-test.iob corpus/spancat/
        --spans-key ${vars.spans_key}
        --converter auto
    deps:
      - assets/anem-train.iob
      - assets/anem-test.iob
    outputs:
      - corpus/spancat/anem-train.spacy
      - corpus/spancat/anem-dev.spacy
      - corpus/spancat/anem-test.spacy
  

  - name: "convert-anem-ents"
    help: "Convert AnEM dataset into the spaCy format"
    script:
      - >-
        python -m scripts.convert_to_spans
        assets/anem-train.iob corpus/ner/
        --use-ents
        --converter auto
        --train-size 0.8
        --seed 42
        --shuffle
      - mv corpus/ner/anem-train-dev.spacy corpus/ner/anem-dev.spacy
      - >-
        python -m scripts.convert_to_spans
        assets/anem-test.iob corpus/ner/
        --use-ents
        --converter auto
    deps:
      - assets/anem-train.iob
      - assets/anem-test.iob
    outputs:
      - corpus/ner/anem-train.spacy
      - corpus/ner/anem-dev.spacy
      - corpus/ner/anem-test.spacy
  
  - name: "inspect-anem"
    help: "Analyze span-characteristics"
    script:
      - >-
        python -m spacy debug data configs/spancat_default.cfg 
        --paths.train corpus/spancat/anem-train.spacy 
        --paths.dev corpus/spancat/anem-dev.spacy
  
  - name: "unpack-finer"
    help: "Prepare the FiNER dataset."
    script:
      - mkdir temp
      - unzip assets/finer139.zip -d temp
      - python scripts/prepare_finer.py
      - rm -rf temp

  - name: "convert-finer-ents"
    help: "Convert FiNER dataset into the spaCy format"
    script:
      - >-
        python -m scripts.convert_to_spans
        assets/finer-train.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/finer-dev.iob corpus/ner/
        --use-ents
      - >-
        python -m scripts.convert_to_spans
        assets/finer-test.iob corpus/ner/
        --use-ents
    deps:
      - assets/finer-train.iob
      - assets/finer-dev.iob
      - assets/finer-test.iob
    outputs:
      - corpus/ner/finer-train.spacy
      - corpus/ner/finer-dev.spacy
      - corpus/ner/finer-test.spacy

  - name: "convert-finer-spans"
    help: "Convert FiNER dataset into the spaCy format"
    script:
      - >-
        python -m scripts.convert_to_spans
        assets/finer-train.iob corpus/spancat/
        --spans-key ${vars.spans_key}
      - >-
        python -m scripts.convert_to_spans
        assets/finer-dev.iob corpus/spancat/
        --spans-key ${vars.spans_key}
      - >-
        python -m scripts.convert_to_spans
        assets/finer-test.iob corpus/spancat/
        --spans-key ${vars.spans_key}
    deps:
      - assets/finer-train.iob
      - assets/finer-dev.iob
      - assets/finer-test.iob
    outputs:
      - corpus/spancat/finer-train.spacy
      - corpus/spancat/finer-dev.spacy
      - corpus/spancat/finer-test.spacy

  - name: "inspect-finer"
    help: "Analyze span-characteristics"
    script:
      - >-
        python -m spacy debug data configs/spancat_default.cfg 
        --paths.train corpus/spancat/finer-train.spacy 
        --paths.dev corpus/spancat/finer-dev.spacy
  
  - name: "generate-unseen"
    help: "Create unseen entities splits for all preprocessed datasets."
    script:
      - python scripts/generate_unseen.py
