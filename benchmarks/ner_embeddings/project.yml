title: "Comparing embedding layers in spaCy"
description: |
  This project compares `MultiHashEmbed` with its standard embedding counterpart
  `MultiEmbed` for Named Entity Recognition. In order to access the datasets,
  you first need to clone the [`spancat-datasets`](https://github.com/explosion/spancat-datasets)
  repository:

  ```sh
  # Clone the spancat-datasets repo to access the datasets
  git clone git@github.com:explosion/spancat-datasets.git
  ```

  and run the necessary conversion scripts. For example, let's perform the
  conversion command for the [Anatomical Entity Mention (AnEM)](http://www.nactem.ac.uk/anatomy/)
  corpus:

  ```sh
  # While inside the spancat-datasets repository
  spacy project run anem
  ```

  This will generate the spaCy files that you can use for training. Once done,
  you **should copy these files to this project**. For example, you can perform
  a directory copy in Linux via:

  ```sh
  cp -r spancat-datasets/corpus/ner/*. ner_embeddings/corpus/. 
  ```

  You can now supply the local path to the commands and workflows to
  perform experiments in **this project:**

  ```sh
  # Perform experiments in the ner_embeddings project
  spacy project run train . --vars.dataset anem
  ```

vars:
  ner_config: "ner_multiembed"
  dataset: "anem"
  language: "en"
  vectors: "vectors/fasttext-en"
  tables_path: "tables"
  metrics_dir: "metrics"
  attrs: "'NORM', 'PREFIX', 'SUFFIX', 'SHAPE'"
  rows: "[5000, 2500, 2500, 2500]"
  include_static_vectors: true
  min_freq: 10
  gpu_id: 0
  seed: 42

directories:
  - "assets"
  - "configs"
  - "corpus"
  - "scripts"
  - "training"
  - "metrics"
  - "vectors"
  - "tables"
  - "debug"

workflows:
  setup:
    - "download-models"
    - "init-fasttext"
    - "make-tables"

assets:
  - dest: "assets/fasttext.en.gz"
    description: "English fastText vectors."
    url: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz
  - dest: "assets/fasttext.es.gz"
    description: "Spanish fastText vectors."
    url: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz
  - dest: "assets/fasttext.nl.gz"
    description: "Dutch fastText vectors."
    url: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.nl.300.vec.gz

commands:
  - name: "download-models"
    help: "Download spaCy models for their word-embeddings."
    script:
      - "python -m spacy download en_core_web_lg"
      - "python -m spacy download es_core_news_lg"
      - "python -m spacy download nl_core_news_lg"

  - name: "init-fasttext"
    help: "Initialize the FastText vectors."
    script:
      - "gzip -d assets/fasttext.en.gz"
      - "gzip -d assets/fasttext.es.gz"
      - "gzip -d assets/fasttext.nl.gz"
      - "python -m spacy init vectors en assets/fasttext.en vectors/fasttext-en"
      - "python -m spacy init vectors es assets/fasttext.es vectors/fasttext-es"
      - "python -m spacy init vectors nl assets/fasttext.nl vectors/fasttext-nl"

  - name: "make-tables"
    help: "Pre-compute token-to-id tables for MultiEmbed."
    script:
      - >-
        python -m scripts.token_map
        configs/${vars.ner_config}.cfg
        ${vars.tables_path}/${vars.dataset}
        --min-freq ${vars.min_freq}
        --paths.train corpus/${vars.dataset}-train.spacy
        --paths.dev corpus/${vars.dataset}-dev.spacy
        --code scripts/custom_components.py
        --paths.tables ${vars.tables_path}

  - name: "train"
    help: "Train NER model."
    script:
      - >-
        python -m spacy train
        configs/${vars.ner_config}.cfg
        --nlp.lang ${vars.language}
        --output training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
        --paths.train corpus/${vars.dataset}-train.spacy
        --paths.dev corpus/${vars.dataset}-dev.spacy
        --paths.vectors ${vars.vectors}
        --paths.tables ${vars.tables_path}/${vars.dataset}/${vars.dataset}-train.tables
        --components.tok2vec.model.embed.include_static_vectors ${vars.include_static_vectors}
        --system.seed ${vars.seed}
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
    deps:
      - corpus/${vars.dataset}-train.spacy
      - corpus/${vars.dataset}-dev.spacy
    outputs:
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-last
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best

  - name: "train-custom-rows"
    help: "Train NER model."
    script:
      - >-
        python -m spacy train
        configs/${vars.ner_config}.cfg
        --nlp.lang ${vars.language}
        --output training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
        --paths.train corpus/${vars.dataset}-train.spacy
        --paths.dev corpus/${vars.dataset}-dev.spacy
        --paths.vectors ${vars.vectors}
        --paths.tables ${vars.tables_path}/${vars.dataset}/${vars.dataset}-train.tables
        --components.tok2vec.model.embed.include_static_vectors ${vars.include_static_vectors}
        --components.tok2vec.model.embed.rows ${vars.rows}
        --system.seed ${vars.seed}
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
    deps:
      - corpus/${vars.dataset}-train.spacy
      - corpus/${vars.dataset}-dev.spacy
    outputs:
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-last
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best

  - name: "evaluate"
    help: "Evaluate NER model."
    script:
      - mkdir -p ${vars.metrics_dir}/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
      - >-
        python -m spacy evaluate
        training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
        corpus/${vars.dataset}-dev.spacy
        --output ${vars.metrics_dir}/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
    deps:
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
      - corpus/${vars.dataset}-dev.spacy
    outputs:
      - ${vars.metrics_dir}/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json

  - name: "evaluate-unseen"
    help: "Evaluate NER model on unseen entities."
    script:
      - mkdir -p ${vars.metrics_dir}-unseen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
      - >-
        python -m spacy evaluate
        training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
        corpus/${vars.dataset}-dev-unseen.spacy
        --output ${vars.metrics_dir}-unseen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
    deps:
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
      - corpus/${vars.dataset}-dev-unseen.spacy
    outputs:
      - ${vars.metrics_dir}-unseen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
