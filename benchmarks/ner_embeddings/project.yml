title: "Comparing embedding layers in spaCy"
description: |
  This project compares `MultiHashEmbed` with its standard embedding counterpart
  `MultiEmbed` for Named Entity Recognition. In order to download and preprocess the datasets,
  you first need to run the commands in the [span-labeling-datasets](https://github.com/explosion/projects/tree/v3/benchmarks/span-labeling-datasets) project. For example, let's perform the
  conversion command for the [Anatomical Entity Mention (AnEM)](http://www.nactem.ac.uk/anatomy/) corpus:

  ```sh
  # While inside the spancat-datasets repository
  spacy project run anem
  ```

  This will generate the spaCy files that you can use for training. Once done,
  you **should copy these files to this project**. For example, you can perform
  a directory copy in Linux via:

  ```sh
  cp -r spancat-datasets/corpus/ner/*. ner_embeddings/corpus/. 
  ```

  You can now supply the local path to the commands and workflows to
  perform experiments in **this project:**

  ```sh
  # Perform experiments in the ner_embeddings project
  spacy project run train . --vars.dataset anem
  ```

vars:
  ner_config: "multihashembed"
  dataset: "archaeo"
  language: "nl"
  vectors: "nl_core_news_lg"
  tables_path: "tables"
  metrics_dir: "metrics"
  attrs: null
  rows: "[5000, 2500, 2500, 2500]"
  include_static_vectors: true
  min_freq: 10
  gpu_id: 0
  seed: 42
  batch_size: 1000
  num_hashes: 4

directories:
  - "assets"
  - "configs"
  - "corpus"
  - "scripts"
  - "training"
  - "metrics"
  - "vectors"
  - "tables"
  - "debug"

workflows:
  setup:
    - "download-models"
    - "init-fasttext"
    - "prepare-datasets"
    - "make-tables"

  trial:
    - "init-labels"
    - "train"
    - "evaluate"
    - "evaluate-seen-unseen"

assets:
  - dest: "assets/fasttext.en.gz"
    description: "English fastText vectors."
    url: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz
  - dest: "assets/fasttext.es.gz"
    description: "Spanish fastText vectors."
    url: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz
  - dest: "assets/fasttext.nl.gz"
    description: "Dutch fastText vectors."
    url: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.nl.300.vec.gz
  - dest: "span-labeling-datasets"
    git:
      repo: "https://github.com/explosion/projects"
      branch: "v3"
      path: "benchmarks/span-labeling-datasets"

commands:
  
  - name: "prepare-datasets"
    help: "Download and preprocess all available data sets using the span-labeling-datasets project."
    script:
      - "python -m spacy project assets span-labeling-datasets"
      - "python -m spacy project run all span-labeling-datasets"
      - "python -m spacy project run clean-archaeo span-labeling-datasets"
      - "python -m spacy project run generate-unseen span-labeling-datasets"
      - "python -m scripts.cli_util copy-contents span-labeling-datasets/corpus/ner corpus"
      - "python -m scripts.cli_util copy-contents span-labeling-datasets/unseen corpus"
      - "python -m scripts.cli_util remove span-labeling-datasets"


  - name: "download-models"
    help: "Download spaCy models for their word-embeddings."
    script:
      - "python -m spacy download en_core_web_lg"
      - "python -m spacy download es_core_news_lg"
      - "python -m spacy download nl_core_news_lg"
      - "python -m spacy download fi_core_news_lg"

  - name: "init-fasttext"
    help: "Initialize the FastText vectors."
    script:
      - "python -m scripts.cli_util unzip assets/fasttext.en.gz"
      - "python -m scripts.cli_util unzip assets/fasttext.es.gz"
      - "python -m scripts.cli_util unzip assets/fasttext.nl.gz"
      - "python -m spacy init vectors en assets/fasttext.en vectors/fasttext-en"
      - "python -m spacy init vectors es assets/fasttext.es vectors/fasttext-es"
      - "python -m spacy init vectors nl assets/fasttext.nl vectors/fasttext-nl"

  - name: "make-tables"
    help: "Pre-compute token-to-id tables for MultiEmbed."
    script:
      - >-
        python -m scripts.token_map
        configs/multiembed.cfg
        ${vars.tables_path}/${vars.dataset}
        --min-freq ${vars.min_freq}
        --paths.train corpus/${vars.dataset}-train.spacy
        --paths.dev corpus/${vars.dataset}-dev.spacy
        --code scripts/custom_components.py
        --paths.tables ${vars.tables_path}

  - name: "init-labels"
    help: "Initialize labels first before training"
    script:
      - >-
        python -m spacy init labels
        configs/${vars.ner_config}.cfg
        corpus/labels/${vars.dataset}.labels
        --verbose 
        --paths.train corpus/${vars.dataset}-train.spacy
        --paths.dev corpus/${vars.dataset}-dev.spacy
        --paths.tables tables/${vars.dataset}/${vars.dataset}-train.tables
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py

  - name: "train"
    help: "Train NER model."
    script:
      - >-
        python -m spacy train
        configs/${vars.ner_config}.cfg
        --nlp.lang ${vars.language}
        --output training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
        --paths.train corpus/${vars.dataset}-train.spacy
        --paths.dev corpus/${vars.dataset}-dev.spacy
        --paths.vectors ${vars.vectors}
        --paths.tables ${vars.tables_path}/${vars.dataset}/${vars.dataset}-train.tables
        --components.tok2vec.model.embed.include_static_vectors ${vars.include_static_vectors}
        --nlp.batch_size ${vars.batch_size}
        --system.seed ${vars.seed}
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
    deps:
      - corpus/${vars.dataset}-train.spacy
      - corpus/${vars.dataset}-dev.spacy
    outputs:
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-last
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best

  - name: "train-adjust-rows"
    help: "Train NER model with adjustable number of rows."
    script:
      - >-
        python -m spacy train
        configs/${vars.ner_config}.cfg
        --nlp.lang ${vars.language}
        --output training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
        --paths.train corpus/${vars.dataset}-train.spacy
        --paths.dev corpus/${vars.dataset}-dev.spacy
        --paths.vectors ${vars.vectors}
        --paths.tables ${vars.tables_path}/${vars.dataset}/${vars.dataset}-train.tables
        --components.tok2vec.model.embed.include_static_vectors ${vars.include_static_vectors}
        --components.tok2vec.model.embed.rows '${vars.rows}'
        --nlp.batch_size ${vars.batch_size}
        --system.seed ${vars.seed}
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
    deps:
      - corpus/${vars.dataset}-train.spacy
      - corpus/${vars.dataset}-dev.spacy
    outputs:
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-last
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best

  - name: "train-hash"
    help: "Train NER model with different number of hash functions."
    script:
      - >-
        python -m spacy train
        configs/${vars.ner_config}.cfg
        --nlp.lang ${vars.language}
        --output training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
        --paths.train corpus/${vars.dataset}-train.spacy
        --paths.dev corpus/${vars.dataset}-dev.spacy
        --paths.vectors ${vars.vectors}
        --paths.tables ${vars.tables_path}/${vars.dataset}/${vars.dataset}-train.tables
        --components.tok2vec.model.embed.include_static_vectors ${vars.include_static_vectors}
        --components.tok2vec.model.embed.num_hashes ${vars.num_hashes}
        --nlp.batch_size ${vars.batch_size}
        --system.seed ${vars.seed}
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
    deps:
      - corpus/${vars.dataset}-train.spacy
      - corpus/${vars.dataset}-dev.spacy
    outputs:
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-last
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best

  - name: "evaluate"
    help: "Evaluate NER model."
    script:
      - mkdir -p ${vars.metrics_dir}/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
      - >-
        python -m spacy evaluate
        training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
        corpus/${vars.dataset}-test.spacy
        --output ${vars.metrics_dir}/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores-test.json
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
      - >-
        python -m spacy evaluate
        training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
        corpus/${vars.dataset}-dev.spacy
        --output ${vars.metrics_dir}/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores-dev.json
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
    deps:
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
      - corpus/${vars.dataset}-dev.spacy
    outputs:
      - ${vars.metrics_dir}/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores-test.json
      - ${vars.metrics_dir}/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores-dev.json

  - name: "evaluate-seen-unseen"
    help: "Evaluate NER model on seen and unseen entities separately."
    script:
      - mkdir -p ${vars.metrics_dir}-dev-unseen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
      - >-
        python -m spacy evaluate
        training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
        corpus/${vars.dataset}-dev-unseen.spacy
        --output ${vars.metrics_dir}-dev-unseen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
      - mkdir -p ${vars.metrics_dir}-test-unseen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
      - >-
        python -m spacy evaluate
        training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
        corpus/${vars.dataset}-test-unseen.spacy
        --output ${vars.metrics_dir}-test-unseen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
      - mkdir -p ${vars.metrics_dir}-dev-seen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
      - >-
        python -m spacy evaluate
        training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
        corpus/${vars.dataset}-dev-seen.spacy
        --output ${vars.metrics_dir}-dev-seen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
      - mkdir -p ${vars.metrics_dir}-test-seen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/
      - >-
        python -m spacy evaluate
        training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
        corpus/${vars.dataset}-test-seen.spacy
        --output ${vars.metrics_dir}-test-seen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
        --gpu-id ${vars.gpu_id}
        --code scripts/custom_components.py
    deps:
      - training/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/model-best
      - corpus/${vars.dataset}-dev-unseen.spacy
      - corpus/${vars.dataset}-test-unseen.spacy
      - corpus/${vars.dataset}-dev-seen.spacy
      - corpus/${vars.dataset}-test-seen.spacy
    outputs:
      - ${vars.metrics_dir}-dev-unseen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
      - ${vars.metrics_dir}-test-unseen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
      - ${vars.metrics_dir}-dev-seen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
      - ${vars.metrics_dir}-test-seen/${vars.dataset}/${vars.vectors}/${vars.ner_config}/${vars.seed}/scores.json
