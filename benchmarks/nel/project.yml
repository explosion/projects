title: 'NEL Benchmark'
description: "Pipeline for benchmarking NEL approaches (incl. candidate generation and entity disambiguation)."
vars:
  name: "nel_benchmark"
  config: "nel.cfg"
  vectors_model: "en_core_web_md"
  version: "0.0.1"

directories: ["assets", "training", "configs", "scripts", "corpora", "temp"]

assets:
  - dest: 'assets/reddit.zip'
    url: 'https://zenodo.org/record/3970806/files/reddit_el.zip?download=1'
    checksum: 'eea345cc7574a5c9c376748d1871d557'
    description: Entity linking dataset scraped from Reddit. See [paper](https://arxiv.org/abs/2101.01228).
  - dest: 'assets/wiki/wikidata_entity_dump.json.bz2'
    url: 'https://dumps.wikimedia.org/wikidatawiki/entities/latest-all.json.bz2'
    description: Wikidata entity dump.
  - dest: 'assets/wiki/wikipedia_dump.xml.bz2'
    url: 'https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles-multistream.xml.bz2'
    description: Wikipedia dump.

workflows:
  all:
    - download_mewsli-9
    - setup
    - preprocess
    - download_model
    - parse_wiki_dumps
    - create_kb
    - compile_corpora
    - train
    - evaluate
  training:
    - create_kb
    - compile_corpora
    - train
    - evaluate

commands:
  - name: download_mewsli-9
    help: Download Mewsli-9 dataset.
    script:
      - bash scripts/datasets/download_mewsli-9.sh

  - name: setup
    help: Install dependencies
    script:
      - "python -m pip install -r requirements.txt"
    deps:
      - "requirements.txt"

  - name: preprocess
    help: Preprocess test datasets
    script:
      - "unzip -q -d assets/reddit assets/reddit.zip"
      - "python ./scripts/clean_data.py reddit"
      - "python ./scripts/clean_data.py mewsli-9"
    deps:
      - "assets/reddit.zip"
      - "assets/mewsli_9"
    outputs:
      - "assets/reddit"
      - "assets/mewsli_9"

  - name: download_model
    help: "Download a model with pretrained vectors and NER component"
    script:
      - "python -m spacy download ${vars.vectors_model}"

  - name: parse_wiki_dumps
    help: "Parses Wikipedia dumps."
    script:
      - "env PYTHONPATH=scripts python ./scripts/parse_wiki_dumps.py"

  - name: create_kb
    help: "Create the knowledge base and write it to file"
    script:
      - "python ./scripts/create_kb.py reddit ${vars.vectors_model} 25"
#      - "python ./scripts/create_kb.py mewsli_9 ${vars.vectors_model} 25"
    deps:
      - "assets/reddit"
#      - "assets/mewsli_9"
    outputs:
      - "assets/reddit/entities.pkl"
      - "assets/reddit/entities_failed_lookup.pkl"
      - "assets/reddit/annotations.pkl"
#      - "assets/mewsli_9/entities.pkl"
#      - "assets/mewsli_9/entities_failed_lookup.pkl"
#      - "assets/mewsli_9/annotations.pkl"
    outputs_no_cache:
      - "temp/reddit/kb"
      - "temp/reddit/nlp"
#      - "temp/mewsli_9/kb"
#      - "temp/mewsli_9/nlp"

  - name: compile_corpora
    help: "Compile corpora, separated in in train/dev/test sets"
    script:
      - "python ./scripts/compile_corpora.py reddit"
#      - "python ./scripts/compile_corpora.py mewsli_9"
    deps:
      - "assets/reddit/entities.pkl"
      - "assets/reddit/entities_failed_lookups.pkl"
      - "assets/reddit/annotations.pkl"
#      - "assets/mewsli_9/entities.pkl"
#      - "assets/mewsli_9/entities_failed_lookups.pkl"
#      - "assets/mewsli_9/annotations.pkl"
      - "temp/reddit/kb"
      - "temp/reddit/nlp"
#      - "temp/mewsli_9/kb"
#      - "temp/mewsli_9/nlp"
      - "configs/datasets.yml"
    outputs_no_cache:
      - "corpora/reddit/train.spacy"
      - "corpora/reddit/dev.spacy"
      - "corpora/reddit/test.spacy"
#      - "corpora/mewsli_9/train.spacy"
#      - "corpora/mewsli_9/dev.spacy"
#      - "corpora/mewsli_9/test.spacy"

  - name: train
    help: "Train a new Entity Linking component. Pass --gpu_id GPU_ID to train with GPU"
    script:
      - "bash scripts/train.sh reddit ${vars.config}"
#      - "python -m spacy train configs/${vars.config} \
#          --paths.dataset_name mewsli_9 \
#          --output training/mewsli_9 \
#          --paths.train corpora/mewsli_9/train.spacy \
#          --paths.dev corpora/mewsli_9/dev.spacy \
#          --paths.kb temp/mewsli_9/kb \
#          --paths.base_nlp temp/mewsli_9/nlp \
#          -c scripts/custom_functions.py"
    deps:
      - "temp/reddit/kb"
      - "temp/reddit/nlp"
      - "corpora/reddit/train.spacy"
      - "corpora/reddit/dev.spacy"
#      - "temp/mewsli_9/kb"
#      - "temp/mewsli_9/nlp"
#      - "corpora/mewsli_9/train.spacy"
#      - "corpora/mewsli_9/dev.spacy"

  - name: evaluate
    help: "Evaluation on the test set"
    script:
      - "env PYTHONPATH=. python ./scripts/evaluate.py reddit"
#      - "env PYTHONPATH=. python ./scripts/evaluate.py mewsli_9"
    deps:
      - "training/reddit/model-best"
      - "corpora/reddit/dev.spacy"
#      - "training/mewsli_9/model-best"
#      - "corpora/mewsli_9/dev.spacy"

  - name: clean
    help: "Remove intermediate files"
    script:
      - "rm -rf training/*"
      - "rm -rf corpora/*"
      - "rm -rf temp/*"
      - "rm -rf assets/reddit"
      - "rm -rf assets/mewsli_9"
