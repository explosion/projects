title: 'Disambiguation of "Emerson" mentions in sentences (Entity Linking)'
description: "**This project was created as part of a [step-by-step video tutorial](https://www.youtube.com/watch?v=8u57WSXVpmw).** It uses [spaCy](https://spacy.io)'s entity linking functionality and [Prodigy](https://prodi.gy) to disambiguate \"Emerson\" mentions in text to unique identifiers from Wikidata. As an example use-case, we consider three different people called Emerson: [an Australian tennis player](https://www.wikidata.org/wiki/Q312545), [an American writer](https://www.wikidata.org/wiki/Q48226), and a [Brazilian footballer](https://www.wikidata.org/wiki/Q215952). [See here](https://github.com/explosion/projects/tree/master/nel-emerson) for the previous scripts for spaCy v2.x."
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  name: "nel_emerson"
  config: "nel.cfg"
  vectors_model: "en_core_web_md"
  annotations: "emerson_annotated_text.jsonl"
  entities: "entities.csv"
  kb: "my_kb"
  nlp: "my_nlp"
  train: "train"
  dev: "dev"
  version: "0.0.2"

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "training", "configs", "scripts", "corpus", "notebooks", "temp"]

# Assets that should be downloaded or available in the directory. We're shipping
# some of them with the project, so they won't have to be downloaded. But the
# 'project assets' command still lets you verify that the checksums match.
assets:
  - dest: "assets/${vars.annotations}"
    description: "The annotated data"
    checksum: "2863586d7b648536f84280648ab32490"
  - dest: "assets/${vars.entities}"
    description: "The entities in the knowledge base"
    checksum: "f24d983db0cd3d180a135bbbbb0d0b8a"
  - dest: "assets/emerson_input_text.txt"
    description: "The original input text"
    checksum: "b5bc61375680396017337e3ebe830ada"

# Workflows are sequences of commands (see below) executed in order. You can
# run them via "spacy project run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
workflows:
  all:
    - setup
    - download
    - kb
    - corpus
    - train
    - evaluate
  training:
    - kb
    - corpus
    - train
    - evaluate

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: download
    help: "Download a spaCy model with pretrained vectors"
    script:
      - "python -m spacy download ${vars.vectors_model}"

  - name: kb
    help: "Create the Knowledge Base in spaCy and write it to file"
    script:
      - "python ./scripts/create_kb.py ./assets/${vars.entities} ${vars.vectors_model} ./temp/${vars.kb} ./temp/${vars.nlp}/"
    deps:
      - "assets/${vars.entities}"
    outputs_no_cache:
      - "temp/${vars.kb}"
      - "temp/${vars.nlp}"

  - name: corpus
    help: "Create a training and dev set from the manually annotated data"
    script:
      - "python ./scripts/create_corpus.py ./assets/${vars.annotations} ./temp/${vars.nlp}/ corpus/${vars.train}.spacy corpus/${vars.dev}.spacy"
    deps:
      - "assets/${vars.annotations}"
    outputs_no_cache:
      - "corpus/${vars.train}.spacy"
      - "corpus/${vars.dev}.spacy"

  - name: train
    help: "Train a new Entity Linking component"
    script:
      - "python -m spacy train configs/${vars.config} --output training --paths.train corpus/${vars.train}.spacy --paths.dev corpus/${vars.dev}.spacy --paths.kb temp/${vars.kb} --paths.base_nlp temp/${vars.nlp} -c scripts/custom_functions.py"
    deps:
      - "temp/${vars.kb}"
      - "temp/${vars.nlp}"
      - "corpus/${vars.train}.spacy"
      - "corpus/${vars.dev}.spacy"

  - name: evaluate
    help: "Final evaluation on the dev data and printing the results"
    script:
      - "python ./scripts/evaluate.py ./training/model-best/ corpus/${vars.dev}.spacy"
    deps:
      - "training/model-best"
      - "corpus/${vars.dev}.spacy"

  # These are additional custom commands that are not run as part of the main
  # "run" list. They can depend on third-party libraries etc. Here are just
  # some examples of what's possible.
  - name: setup
    help: Install dependencies
    script:
      - "python -m pip install -r requirements.txt"
    deps:
      - "requirements.txt"

  - name: clean
    help: "Remove intermediate files"
    script:
      - "rm -rf training/*"
      - "rm -rf corpus/*"
      - "rm -rf temp/${vars.kb}"
      - "rm -rf temp/${vars.nlp}"
