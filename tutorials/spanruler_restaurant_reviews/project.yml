title: "Using SpanRuler for rule-based Named Entity Recognition"
description: |
  This example project demonstrates how you can use the
  [SpanRuler](https://spacy.io/api/spanruler) component for rule-based named
  entity recognition (NER). In spaCy v3 and below, this functionality can be
  achieved via the [EntityRuler](https://spacy.io/api/entityruler). However, 
  we will start **deprecating** the `entity_ruler` component in favor of
  `span_ruler` in v4.

  Here, we will be using the **MIT Restaurant dataset** (Liu, et al, 2013) to
  determine entities such as *Rating*, *Location*, *Restaurant_Name*,
  *Price*, *Dish*, *Amenity*,  and *Cuisine* from restaurant reviews.
  Below are a few examples from the training data:

  ![](figures/example_00.png)
  ![](figures/example_01.png)
  ![](figures/example_02.png)

  First, we will train an NER-only model and treat it as our baseline. Then, we will
  attach the `SpanRuler` component **before the `ner` component** of the existing
  pipeline. This setup gives us two pipelines we can compare upon.

  We will create rules for `Price`, `Rating`, `Hours`, `Amenity`, and `Location`
  because they have discernible patterns we can encode. The same cannot be said
  for `Restaurant_Name` and `Dish`, so we'll leave them as they are. Here are
  some rules we included in the patterns file (`patterns.jsonl`):

  | Label  | Pattern / Examples                                    | Description                                                                 |
  |--------|-------------------------------------------------------|-----------------------------------------------------------------------------|
  | Price  | `cheap(est)?`, `(in)?expensive` | Reviewers do not often give the exact dollar amount but rather describe it. |
  | Rating | `good`, `great`, `fancy`                                      | Reviewers often describe the dish rather than giving an exact rating        |
  | Rating | `\d(-\|\s)?star(s)?`                                     | Reviewers can also give star ratings (5-star, 3-stars, 2 star) on a dish.   |
  | Rating | `(one\|two\|three\|four\|five)\sstar(s)?`                  | Same as above but using words (four star, five star rating) instead of numbers. |
  | Rating | `michelin`, `michelin rated`                  | Reviews also mention if a restaurant has a Michelin star. |
  | Amenity | `master card`, `take credit card`                  | Amenities mention different payment options. |
  | Amenity | `classy`, `clean`                  | Amenities also include adjectives that describe the restaurant. |
  | Location | `in harold square`, `airport`                  | Location also mentions nearby landmarks for a restaurant. |

  If we look at the results, we see an increase in performance for the majority
  of entities with rules:

  |          | NER only  | With Spanruler  |
  |----------|-----------|-----------------|
  | Price    | **83.72** | 82.90           |
  | Rating   | 77.21     | **77.78**       |
  | Hours    | 64.78     | **64.78**       |
  | Amenity  | 66.67     | **66.98**       |
  | Location | 81.17     | **81.20**       |

  Overall, we have better performance for the combined `ner` and `span_ruler`
  pipeline with just a non-exhaustive set of rules.

  |           | NER only | With Spanruler |
  |-----------|----------|----------------|
  | Precision | 77.58    | **77.63**      |
  | Recall    | 76.23    | **76.32**      |
  | F-score   | 76.90    | **76.97**      |

  **Reference**

  - J. Liu, P. Pasupat, S. Cyphers, and J. Glass. 2013. Asgard: A portable
  architecture for multilingual dialogue systems. In *2013 IEEE International
  Conference on Acoustics, Speech and Signal Processing*, pages 8386-8390

# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  name: "spanruler_restaurant_reviews"
  seed: 0
  gpu_id: -1
  vectors: "en_core_web_lg"
  spanruler_location: before

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories:
  ["assets", "corpus", "configs", "metrics", "models", "scripts", "training"]

# Assets that should be downloaded or available in the directory.
assets:
  - dest: "assets/train_raw.iob"
    url: https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio
    description: "Training data from the MIT Restaurants Review dataset"
  - dest: "assets/test_raw.iob"
    url: https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio
    description: "Test data from the MIT Restaurants Review dataset"

# Workflows are sequences of commands (see below) executed in order. You can
# run them via "spacy project run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
workflows:
  all:
    - download
    - preprocess
    - convert
    - split
    - train
    - assemble
    - evaluate

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: "download"
    help: "Download a spaCy model with pretrained vectors."
    script:
      - "python -m spacy download ${vars.vectors}"

  - name: "preprocess"
    help: "Format and process the raw IOB datasets to make them compatible with spaCy convert."
    script:
      - "python -m scripts.preprocess assets/train_raw.iob assets/train.iob"
      - "python -m scripts.preprocess assets/test_raw.iob assets/test.iob"
    deps:
      - assets/train_raw.iob
      - assets/test_raw.iob
    outputs:
      - assets/train.iob
      - assets/test.iob

  - name: "convert"
    help: "Convert the data to spaCy's binary format."
    script:
      - "python -m spacy convert assets/train.iob corpus/"
      - "python -m spacy convert assets/test.iob corpus/"
      - "mv corpus/train.spacy corpus/train_dev.spacy"
    deps:
      - assets/train.iob
      - assets/test.iob
    outputs:
      - corpus/train_dev.spacy
      - corpus/test.spacy

  - name: "split"
    help: "Split the train-dev dataset."
    script:
      - "python -m scripts.split corpus/train_dev.spacy corpus/ --train-size 0.8 --seed ${vars.seed}"
    deps:
      - corpus/train_dev.spacy
    outputs:
      - corpus/train.spacy
      - corpus/dev.spacy

  - name: "train"
    help: "Train a baseline NER model."
    script:
      - >-
        python -m spacy train configs/ner.cfg
        --paths.train corpus/train.spacy
        --paths.dev corpus/dev.spacy
        --paths.vectors ${vars.vectors}
        --output training/ner/
        --gpu-id ${vars.gpu_id}
    deps:
      - corpus/train.spacy
      - corpus/dev.spacy
    outputs:
      - training/ner/model-best
      - training/ner/model-last

  - name: "assemble"
    help: "Assemble trained NER pipeline with SpanRuler."
    script:
      - >-
        python -m spacy assemble
        configs/ner_ruler.cfg
        models/ner_ruler
        --components.tok2vec.source training/ner/model-best/
        --components.ner.source training/ner/model-best/
        --code scripts/rules.py
    deps:
      - training/ner/model-best
    outputs:
      - models/ner_ruler

  - name: "evaluate"
    help: "Evaluate each model."
    script:
      - >-
        python -m spacy evaluate
        training/ner/model-best/
        corpus/test.spacy
        --gpu-id ${vars.gpu_id}
        --output metrics/baseline.json

      - >-
        python -m spacy evaluate
        models/ner_ruler/
        corpus/test.spacy
        --gpu-id ${vars.gpu_id}
        --output metrics/combined.json
    deps:
      - training/ner/model-best/
      - models/ner_ruler
    outputs:
      - metrics/baseline.json
      - metric/combined.json
