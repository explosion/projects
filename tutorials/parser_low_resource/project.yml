title: "Training a POS tagger and dependency parser for a low-resource language"
description: |
  This project trains a part-of-speech tagger and dependency parser for a
  low-resource language such as Tagalog. We will be using the
  [TRG](https://universaldependencies.org/treebanks/tl_trg/index.html) and
  [Ugnayan](https://universaldependencies.org/treebanks/tl_ugnayan/index.html)
  treebanks for this task. Since the number of sentences in each corpus is
  small, we'll need to evaluate our model using [10-fold cross
  validation](https://universaldependencies.org/release_checklist.html#data-split).
  How to implement this split will be demonstrated in this project
  (`scripts/kfold.py`). The cross validation results can be seen below.

  ### 10-fold Cross-validation results

  |         | TOKEN_ACC | POS_ACC | MORPH_ACC | TAG_ACC | DEP_UAS | DEP_LAS |
  |---------|-----------|---------|-----------|---------|---------|---------|
  | TRG     | **1.000**     | **0.843**   | 0.749     | **0.833**   | *80.846**   | **0.554**   |
  | Ugnayan | 0.998     | 0.819   | **0.995**     | 0.810   | 0.667   | 0.409   |

directories: ["assets", "corpus", "training", "metrics", "configs", "models"]

vars:
  config: "default"
  gpu_id: -1
  n_folds: 10
  seed: 42
  lang: "tl"
  trg_treebank: "UD_Tagalog-TRG"
  trg_data: "tl_trg-ud-test"
  ugn_treebank: "UD_Tagalog-Ugnayan"
  ugn_data: "tl_ugnayan-ud-test"

assets:
  - dest: "assets/${vars.trg_data}.conllu"
    description: "Treebank data for UD_Tagalog-TRG"
    url: "https://raw.githubusercontent.com/UniversalDependencies/UD_Tagalog-TRG/master/tl_trg-ud-test.conllu"
  - dest: "assets/${vars.ugn_data}.conllu"
    description: "Treebank data for UD_Tagalog-Ugnayan"
    url: "https://raw.githubusercontent.com/UniversalDependencies/UD_Tagalog-Ugnayan/master/tl_ugnayan-ud-test.conllu"

workflows:
  all:
    - preprocess
    - evaluate-kfold

commands:
  - name: preprocess
    help: "Convert the data to spaCy's format"
    script:
      - >-
        python -m spacy convert 
        assets/${vars.trg_data}.conllu
        corpus/
        --converter conllu
        --n-sents 1
        --merge-subtokens
      - >-
        python -m spacy convert 
        assets/${vars.ugn_data}.conllu
        corpus/
        --converter conllu
        --n-sents 1
        --merge-subtokens
    deps:
      - "assets/${vars.trg_data}.conllu"
      - "assets/${vars.ugn_data}.conllu"
    outputs:
      - "corpus/${vars.trg_data}.spacy"
      - "corpus/${vars.ugn_data}.spacy"

  - name: "evaluate-kfold"
    help: "Evaluate using k-fold cross validation"
    script:
      - >-
        python -m scripts.kfold 
        corpus/${vars.trg_data}.spacy 
        configs/${vars.config}.cfg 
        --output-path metrics/${vars.trg_data}-kfold.json 
        --n-folds ${vars.n_folds}
        --lang ${vars.lang} 
        --system.seed ${vars.seed}
        --use-gpu ${vars.gpu_id}
      - >-
        python -m scripts.kfold 
        corpus/${vars.ugn_data}.spacy 
        configs/${vars.config}.cfg 
        --output-path metrics/${vars.ugn_data}-kfold.json 
        --n-folds ${vars.n_folds}
        --lang ${vars.lang} 
        --system.seed ${vars.seed}
        --use-gpu ${vars.gpu_id}
    deps:
      - "corpus/${vars.trg_data}.spacy"
      - "corpus/${vars.ugn_data}.spacy"
      - "configs/${vars.config}.cfg"
      - "scripts/kfold.py"
    outputs:
      - "metrics/${vars.trg_data}-kfold.json"
      - "metrics/${vars.ugn_data}-kfold.json"

  - name: "clean"
    help: "Remove intermediate files"
    script:
      - "rm -rf training/*"
      - "rm -rf corpus/*"
      - "rm -rf metrics/*"
